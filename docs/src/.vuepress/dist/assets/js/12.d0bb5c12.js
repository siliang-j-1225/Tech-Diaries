(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{393:function(t,e,a){"use strict";a.r(e);var s=a(42),n=Object(s.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"how-to-create-a-parallelrunstep-in-azure-ml-studio"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#how-to-create-a-parallelrunstep-in-azure-ml-studio"}},[t._v("#")]),t._v(" How to create a ParallelRunStep in Azure ML Studio")]),t._v(" "),a("h2",{attrs:{id:"what-is-azure-ml-pipeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#what-is-azure-ml-pipeline"}},[t._v("#")]),t._v(" What is Azure ML pipeline")]),t._v(" "),a("p",[t._v("You may have already known about how to use Azure ML to build a pipeline and easily create and maintain your own models.")]),t._v(" "),a("p",[t._v("If not yet, have a look of "),a("a",{attrs:{href:"https://azure.microsoft.com/en-us/services/machine-learning/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Azure Machine Learning"),a("OutboundLink")],1),t._v(".")]),t._v(" "),a("p",[t._v("Azure ML offers a useful functionality of creating ML pipelines as a workflow which can assembly various ML phases. The pipeline can be published for reusing and sharing with others. Access\n"),a("a",{attrs:{href:"https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-your-first-pipeline",target:"_blank",rel:"noopener noreferrer"}},[t._v("How to create your first pipeline"),a("OutboundLink")],1),t._v(" to get more details.")]),t._v(" "),a("p",[t._v("A simple explanation of how to build a pipeline:")]),t._v(" "),a("ul",[a("li",[t._v("Firstly, design your workflow (or pipeline) which consists of a series of ML phases (or steps);")]),t._v(" "),a("li",[t._v("Secondly, develop each of the phases with python scripts;")]),t._v(" "),a("li",[t._v("Thirdly, assembly each of the steps with a "),a("code",[t._v("PythonScriptStep")]),t._v(" and append it to the pipeline; To assembly the step, you will need settings like,\n"),a("ul",[a("li",[t._v("the entry python script developed in the second stage")]),t._v(" "),a("li",[t._v("arguments needed to run the entry script")]),t._v(" "),a("li",[t._v("along with the computing resources to run the step")]),t._v(" "),a("li",[t._v("input of the step")]),t._v(" "),a("li",[t._v("output of the step")])])])]),t._v(" "),a("p",[t._v("When the pipeline being executed, it starts a single compute node (or a node in the compute cluster as you set in the third stage), prepare the data related, and then setup the entry script, and run it.")]),t._v(" "),a("h2",{attrs:{id:"what-is-azure-ml-parallelrunstep"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#what-is-azure-ml-parallelrunstep"}},[t._v("#")]),t._v(" What is Azure ML "),a("code",[t._v("ParallelRunStep")])]),t._v(" "),a("p",[t._v("In some cases you may also need to deal with large amount of data before they can be used to the next steps.")]),t._v(" "),a("p",[t._v("One problem of processing big data is the time it will cost. And a common solution can be thought of here is to process the data in parallel.")]),t._v(" "),a("p",[t._v("Instead of using only one machine to do all the job, you can separate the data into small batches,  distribute the computing to several other machines(assume you have n of them in total), and then process them at the same time, thus each machine only need to process 1/n of the original data amount and you can shorten the time significantly.")]),t._v(" "),a("p",[t._v("Azure ML allows you to implement this solution by using the "),a("code",[t._v("ParallelRunStep")]),t._v(".")]),t._v(" "),a("p",[t._v("Similar to running a normal step with a python script, Azure ML Studio also allows you to process data in parallel by appending a special "),a("code",[t._v("ParallelRunStep")]),t._v(" to the pipeline.")]),t._v(" "),a("p",[t._v("When you add a "),a("code",[t._v("ParallelRunStep")]),t._v(" to an Azure ML pipeline, except for the settings of a normal step, you can also define setting like how many nodes, processes per nodes to run in parallel. When the pipeline being executed, it will start\nThis special pipeline will run your entry script in parallel.")]),t._v(" "),a("p",[t._v("You can find how to setup a "),a("code",[t._v("ParallelRunStep")]),t._v(" from links below,\n"),a("a",{attrs:{href:"https://docs.microsoft.com/en-us/python/api/azureml-contrib-pipeline-steps/azureml.contrib.pipeline.steps.parallelrunstep?view=azure-ml-py",target:"_blank",rel:"noopener noreferrer"}},[t._v("ParallelRunStep Class"),a("OutboundLink")],1),a("br"),t._v(" "),a("a",{attrs:{href:"https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.parallelrunconfig?view=azure-ml-py",target:"_blank",rel:"noopener noreferrer"}},[t._v("ParallelRunConfig Class"),a("OutboundLink")],1),a("br"),t._v(" "),a("a",{attrs:{href:"https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/machine-learning-pipelines/parallel-run",target:"_blank",rel:"noopener noreferrer"}},[t._v("Example: batch-inference-notebooks"),a("OutboundLink")],1)]),t._v(" "),a("h2",{attrs:{id:"some-tips"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#some-tips"}},[t._v("#")]),t._v(" Some tips")]),t._v(" "),a("p",[t._v("Although very similar to a normal step, there are still some differences you may want to take care with. It has taken me longer time to finally figure out how to setup the parallel step correctly.")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("Configs")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("PythonScriptStep")]),t._v(" uses "),a("code",[t._v("RunConfiguration")]),t._v(" of "),a("code",[t._v("azureml.core.runconfig")])]),t._v(" "),a("li",[a("code",[t._v("ParallelRunStep")]),t._v(" uses "),a("code",[t._v("ParallelRunConfig")]),t._v(" of "),a("code",[t._v("azureml.pipeline.steps")])])])]),t._v(" "),a("li",[a("p",[t._v("Parameter "),a("code",[t._v("inputs")])]),t._v(" "),a("ul",[a("li",[a("code",[t._v("inputs")]),t._v(" parameter of "),a("code",[t._v("PythonScriptStep")]),t._v(" can take "),a("code",[t._v("PipelineData")]),t._v(" from previous steps")]),t._v(" "),a("li",[a("code",[t._v("inputs")]),t._v(" parameter of "),a("code",[t._v("ParallelRunStep")]),t._v(" can only take Dataset like object (either "),a("code",[t._v("TabularDataset")]),t._v(" or "),a("code",[t._v("FileDataset")]),t._v(", or "),a("code",[t._v("OutputDatasetConfig")]),t._v(" ) and consume the data with partition to each parallel run.\n"),a("ul",[a("li",[t._v("the equivalent parameter of "),a("code",[t._v("inputs")]),t._v(" in "),a("code",[t._v("PythonScriptStep")]),t._v(" for "),a("code",[t._v("ParallelRunStep")]),t._v(" is called "),a("code",[t._v("side_inputs")])])])])])]),t._v(" "),a("li",[a("p",[t._v("Parameter "),a("code",[t._v("outputs")])]),t._v(" "),a("ul",[a("li",[a("code",[t._v("outputs")]),t._v(" parameter of "),a("code",[t._v("PythonScriptStep")]),t._v(" can take "),a("code",[t._v("PipelineData")]),t._v(" for next steps")]),t._v(" "),a("li",[a("code",[t._v("ParallelRunStep")]),t._v(" does not have "),a("code",[t._v("outputs")]),t._v(" parameter, it only has "),a("code",[t._v("output")]),t._v(", which means it can not ouput to multiple "),a("code",[t._v("PipelineData")]),t._v(".")])])]),t._v(" "),a("li",[a("p",[t._v("Entry script")]),t._v(" "),a("ul",[a("li",[t._v("the entry script used by "),a("code",[t._v("PythonScriptStep")]),t._v(" requires only one "),a("code",[t._v("run(*args, **kwargs)")]),t._v(" function.")]),t._v(" "),a("li",[t._v("the entry script used by "),a("code",[t._v("ParallelRunStep")]),t._v(" requires one one "),a("code",[t._v("run(mini_batch)")]),t._v(" and one "),a("code",[t._v("init()")]),t._v(" function. "),a("code",[t._v("run(mini_batch)")]),t._v(" must have only one parameter as the input consuming data, and init() must have no parameter. If you want to pass parameters to your entry script, please specify them in 'arguments' in ParallelRunStep. And then get the parameters using argparse.")])])])]),t._v(" "),a("h1",{attrs:{id:"example"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example"}},[t._v("#")]),t._v(" Example")]),t._v(" "),a("p",[t._v("Example of how to create "),a("code",[t._v("ParallelRunStep")]),t._v(" with consuming data from previous step:")]),t._v(" "),a("p",[t._v("Create the "),a("code",[t._v("PipelineData")]),t._v(" to be used to pass data between steps.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("prep_step_pipelinedata "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PipelineData"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prep_step_pipelinedata "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" is_directory"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nparal_step_pipelinedata "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PipelineData"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"paral_step_pipelinedata"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" is_directory"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    \n")])])]),a("p",[t._v("Create the "),a("code",[t._v("PipelineData")]),t._v(" to be consumed as partition data, and promote it to Dataset.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("consuming_pipelinedata "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PipelineData"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'consuming_rules_file'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" is_directory"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("as_dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Create the previous step, "),a("strong",[t._v("set the consuming dataset in the "),a("code",[t._v("outputs")])]),t._v(".\nThus inside the entry script of previous "),a("code",[t._v("PythonScriptStep")]),t._v(", you can save the data to "),a("code",[t._v("consuming_pipelinedata")]),t._v("'s path and it will be used as a dataset by next step.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("prep_step "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PythonScriptStep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prep_step"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n            outputs"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("prep_step_pipelinedata "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" consuming_pipelinedata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Create the config for ParallelRunStep,")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("parallel_run_config "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ParallelRunConfig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            source_directory"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"source_directory/"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            entry_script"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"entry_script.py"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            mini_batch_size"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"20"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            error_threshold"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            output_action"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"append_row"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            environment"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("environment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            compute_target"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("compute_target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            node_count"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            process_count_per_node"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            append_row_file_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"parallel_run_output.txt"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[t._v("Create the parallel step, be careful where to set the comsuming dataset and the input pipeline data.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("paral_step "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ParallelRunStep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"parallel"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            inputs"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("consuming_pipelinedata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            side_inputs"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("prep_step_pipelinedata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            output"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("paral_step_pipelinedata "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            arguments"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            parallel_run_config"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("parallel_run_config\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);e.default=n.exports}}]);